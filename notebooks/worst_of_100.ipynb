{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chiche/miniconda3/envs/daug/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import matplotlib.colors as mcolors\n",
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from advbench.datasets import MNIST, STL10\n",
    "from advbench.datasets import to_loaders\n",
    "from advbench.algorithms import ERM, Augmentation, Adversarial_Worst_Of_K, Adversarial_PGD\n",
    "from advbench.attacks import Fo_Adam\n",
    "from advbench import hparams_registry\n",
    "from advbench.lib import  misc\n",
    "import torch\n",
    "from advbench.lib.transformations import se_matrix, angle_to_rotation_matrix, se_transform\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as tt\n",
    "import tarfile\n",
    "from torch import nn\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import matplotlib.colors as mcolors\n",
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from advbench.datasets import MNIST, STL10\n",
    "from advbench.datasets import to_loaders\n",
    "from advbench.algorithms import ERM, Augmentation, Adversarial_Worst_Of_K, Adversarial_PGD\n",
    "from advbench.attacks import Fo_Adam\n",
    "from advbench import hparams_registry\n",
    "from advbench.lib import  misc\n",
    "import torch\n",
    "from advbench.lib.transformations import se_matrix, angle_to_rotation_matrix, se_transform\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from humanfriendly import format_timespan\n",
    "\n",
    "\n",
    "from advbench import datasets\n",
    "from advbench import algorithms\n",
    "from advbench import attacks\n",
    "from advbench import hparams_registry\n",
    "from advbench.lib import misc, meters, plotting, logging\n",
    "from torch.cuda.amp import autocast\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(weight_path, dataset, device=\"cuda:1\"):       \n",
    "        algorithm = ERM(\n",
    "        dataset.INPUT_SHAPE, \n",
    "        dataset.NUM_CLASSES,\n",
    "        hparams,\n",
    "        device).to(device)\n",
    "        w_dict = torch.load(weight_path,map_location='cuda:1')\n",
    "        #print(weight_dict.keys())\n",
    "        #if db==\"mnist\":\n",
    "        weight_dict = {}\n",
    "        for s,v in w_dict.items():\n",
    "                if \"classifier\" in s and \"model\" not in s:\n",
    "                        weight_dict[s.replace('classifier', 'classifier.model')] = v\n",
    "                else:\n",
    "                        weight_dict[s] = v \n",
    "        algorithm.load_state_dict(weight_dict)\n",
    "        return algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for CIFAR100\n",
      "62 runs found\n",
      "TAUG Worst_DALE_PD_Reverse wrn-28-10 0 1at1dctp failed\n",
      "Fetching data for MNIST\n",
      "202 runs found\n",
      "Fetching data for STL10\n",
      "99 runs found\n",
      "restful-leaf-110 o30zljoc failed\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    api = wandb.Api(timeout=50)\n",
    "    dsets = [\"CIFAR100\", \"MNIST\", \"STL10\"]\n",
    "    #results_dfs = {}\n",
    "    entity = \"hounie\"\n",
    "    all_runs_list = []\n",
    "    for dataset in dsets:\n",
    "        print(\"Fetching data for {}\".format(dataset))\n",
    "        project = f\"DAug-{dataset}\"\n",
    "        base = f\"../trained_weights/{project}\"\n",
    "        Path( base ).mkdir( parents=True, exist_ok=True )\n",
    "        runs = api.runs(f\"{entity}/{project}\")\n",
    "        print(f\"{len(runs)} runs found\")\n",
    "        for run in runs:\n",
    "            if run.state == \"finished\":\n",
    "                id = run.id\n",
    "                if True:\n",
    "                    run = api.run(f\"{entity}/{project}/{id}\")\n",
    "                    tmp_path = os.path.join(base, f\"tmp\")\n",
    "                    weight_dir = os.path.join(base, run.name)\n",
    "                    path = os.path.join(weight_dir, f\"{run.id}.pkl\")\n",
    "                    Path( weight_dir ).mkdir( parents=True, exist_ok=True )\n",
    "                    results = {**run.summary, **run.config, \"weights\": path, \"id\": run.id, \"name\":run.name}\n",
    "                    try:\n",
    "                        f = run.file(\"train-output/delta hist_ckpt.pkl\").download(tmp_path, replace=True) \n",
    "                        os.rename(f.name, path)\n",
    "                        all_runs_list.append(results)\n",
    "                    except:\n",
    "                        try:\n",
    "                            run = api.run(f\"{entity}/{project}/{id}\")\n",
    "                            f = run.file(\"train-output/loss_ckpt.pkl\").download(tmp_path, replace=True)\n",
    "                            os.rename(f.name, path)\n",
    "                            all_runs_list.append(results)\n",
    "                        except:\n",
    "                            try:\n",
    "                                run = api.run(f\"{entity}/{project}/{id}\")\n",
    "                                f = run.file(\"train-output/acceptance rate_ckpt.pkl\").download(tmp_path, replace=True)\n",
    "                                os.rename(f.name, path)\n",
    "                                all_runs_list.append(results)\n",
    "                            except:\n",
    "                                print(f\"{run.name} {run.id} failed\")\n",
    "                                pass\n",
    "            #break\n",
    "    df = pd.DataFrame(all_runs_list)\n",
    "    df.to_csv(f\"./results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./results.csv\")\n",
    "test_keys = []\n",
    "train_keys = []\n",
    "for c in df.columns:\n",
    "        if \"loss\" not in c and \"acc\" not in c:\n",
    "            if c.startswith(\"test\"):\n",
    "                test_keys.append(c)\n",
    "                #print(c)\n",
    "            else:\n",
    "                train_keys.append(c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR100 SE\n",
      "Files already downloaded and verified\n",
      "5000\n",
      "model wrn-28-10\n",
      "Using WRN-28-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhounie\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/chiche/advbench/notebooks/wandb/run-20220523_153608-1xsqeenw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"https://wandb.ai/hounie/DAug-CIFAR100/runs/1xsqeenw\" target=\"_blank\">SE Adversarial_Adam wrn-28-10 3</a></strong> to <a href=\"https://wandb.ai/hounie/DAug-CIFAR100\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [10:13,  1.63it/s]\n",
      "500it [05:06,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Worst_Of_100...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_acc_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>test_loss_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>test_loss_adv_mean_Worst_Of_100</td><td>▁</td></tr><tr><td>train_acc_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>train_loss_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>train_loss_adv_mean_Worst_Of_100</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>loss_avg</td><td>0.01097</td></tr><tr><td>lr</td><td>0.0008</td></tr><tr><td>mean_test_acc_advFo_Adam</td><td>50</td></tr><tr><td>mean_test_acc_advFo_PGD</td><td>70</td></tr><tr><td>mean_test_acc_advGaussian_Batch</td><td>59</td></tr><tr><td>mean_test_acc_advLaplacian_Batch</td><td>56</td></tr><tr><td>mean_test_acc_advRand_Aug_Batch</td><td>59</td></tr><tr><td>mean_train_acc_advFo_Adam</td><td>100</td></tr><tr><td>mean_train_acc_advFo_PGD</td><td>100</td></tr><tr><td>mean_train_acc_advGaussian_Batch</td><td>100</td></tr><tr><td>mean_train_acc_advLaplacian_Batch</td><td>100</td></tr><tr><td>mean_train_acc_advRand_Aug_Batch</td><td>100</td></tr><tr><td>step</td><td>10000000</td></tr><tr><td>test_acc_adv_Fo_Adam</td><td>50</td></tr><tr><td>test_acc_adv_Fo_PGD</td><td>70</td></tr><tr><td>test_acc_adv_Gaussian_Batch</td><td>40</td></tr><tr><td>test_acc_adv_Laplacian_Batch</td><td>40</td></tr><tr><td>test_acc_adv_Rand_Aug_Batch</td><td>40</td></tr><tr><td>test_acc_adv_Worst_Of_100</td><td>66.37</td></tr><tr><td>test_clean_acc</td><td>76.91</td></tr><tr><td>test_loss_adv_Fo_Adam</td><td>2.15924</td></tr><tr><td>test_loss_adv_Fo_PGD</td><td>1.69207</td></tr><tr><td>test_loss_adv_Gaussian_Batch</td><td>2.44022</td></tr><tr><td>test_loss_adv_Laplacian_Batch</td><td>2.35091</td></tr><tr><td>test_loss_adv_Rand_Aug_Batch</td><td>2.15003</td></tr><tr><td>test_loss_adv_Worst_Of_100</td><td>1.35452</td></tr><tr><td>test_loss_adv_mean_Fo_Adam</td><td>2.15924</td></tr><tr><td>test_loss_adv_mean_Fo_PGD</td><td>1.69207</td></tr><tr><td>test_loss_adv_mean_Gaussian_Batch</td><td>1.40926</td></tr><tr><td>test_loss_adv_mean_Laplacian_Batch</td><td>1.47451</td></tr><tr><td>test_loss_adv_mean_Rand_Aug_Batch</td><td>1.44519</td></tr><tr><td>test_loss_adv_mean_Worst_Of_100</td><td>1.35452</td></tr><tr><td>train_acc_adv_Fo_Adam</td><td>100</td></tr><tr><td>train_acc_adv_Fo_PGD</td><td>100</td></tr><tr><td>train_acc_adv_Gaussian_Batch</td><td>100</td></tr><tr><td>train_acc_adv_Laplacian_Batch</td><td>100</td></tr><tr><td>train_acc_adv_Rand_Aug_Batch</td><td>100</td></tr><tr><td>train_acc_adv_Worst_Of_100</td><td>94.06</td></tr><tr><td>train_clean_acc</td><td>99.78</td></tr><tr><td>train_loss_adv_Fo_Adam</td><td>0.33557</td></tr><tr><td>train_loss_adv_Fo_PGD</td><td>0.3188</td></tr><tr><td>train_loss_adv_Gaussian_Batch</td><td>0.0529</td></tr><tr><td>train_loss_adv_Laplacian_Batch</td><td>0.00831</td></tr><tr><td>train_loss_adv_Rand_Aug_Batch</td><td>0.00678</td></tr><tr><td>train_loss_adv_Worst_Of_100</td><td>0.39337</td></tr><tr><td>train_loss_adv_mean_Fo_Adam</td><td>2.15924</td></tr><tr><td>train_loss_adv_mean_Fo_PGD</td><td>1.69207</td></tr><tr><td>train_loss_adv_mean_Gaussian_Batch</td><td>1.40926</td></tr><tr><td>train_loss_adv_mean_Laplacian_Batch</td><td>1.47451</td></tr><tr><td>train_loss_adv_mean_Rand_Aug_Batch</td><td>1.44519</td></tr><tr><td>train_loss_adv_mean_Worst_Of_100</td><td>1.35452</td></tr><tr><td>tx</td><td>3</td></tr><tr><td>ty</td><td>3</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">SE Adversarial_Adam wrn-28-10 3</strong>: <a href=\"https://wandb.ai/hounie/DAug-CIFAR100/runs/1xsqeenw\" target=\"_blank\">https://wandb.ai/hounie/DAug-CIFAR100/runs/1xsqeenw</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220523_153608-1xsqeenw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR100 SE\n",
      "Files already downloaded and verified\n",
      "5000\n",
      "model wrn-28-10\n",
      "Using WRN-28-10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/chiche/advbench/notebooks/wandb/run-20220523_155135-3mt3jee1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"https://wandb.ai/hounie/DAug-CIFAR100/runs/3mt3jee1\" target=\"_blank\">SE Gaussian wrn-28-10 0</a></strong> to <a href=\"https://wandb.ai/hounie/DAug-CIFAR100\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [10:10,  1.64it/s]\n",
      "500it [05:07,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Worst_Of_100...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_acc_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>test_loss_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>test_loss_adv_mean_Worst_Of_100</td><td>▁</td></tr><tr><td>train_acc_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>train_loss_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>train_loss_adv_mean_Worst_Of_100</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>loss_avg</td><td>0.0111</td></tr><tr><td>lr</td><td>0.0008</td></tr><tr><td>mean_test_acc_advFo_Adam</td><td>40</td></tr><tr><td>mean_test_acc_advFo_PGD</td><td>70</td></tr><tr><td>mean_test_acc_advGaussian_Batch</td><td>61</td></tr><tr><td>mean_test_acc_advLMC_Laplacian_Linf</td><td>60</td></tr><tr><td>mean_test_acc_advLaplacian_Batch</td><td>62</td></tr><tr><td>mean_test_acc_advRand_Aug_Batch</td><td>56</td></tr><tr><td>mean_train_acc_advFo_Adam</td><td>90</td></tr><tr><td>mean_train_acc_advFo_PGD</td><td>90</td></tr><tr><td>mean_train_acc_advGaussian_Batch</td><td>100</td></tr><tr><td>mean_train_acc_advLMC_Laplacian_Linf</td><td>100</td></tr><tr><td>mean_train_acc_advLaplacian_Batch</td><td>100</td></tr><tr><td>mean_train_acc_advRand_Aug_Batch</td><td>100</td></tr><tr><td>step</td><td>10000000</td></tr><tr><td>test_acc_adv_Fo_Adam</td><td>40</td></tr><tr><td>test_acc_adv_Fo_PGD</td><td>70</td></tr><tr><td>test_acc_adv_Gaussian_Batch</td><td>60</td></tr><tr><td>test_acc_adv_LMC_Laplacian_Linf</td><td>60</td></tr><tr><td>test_acc_adv_Laplacian_Batch</td><td>50</td></tr><tr><td>test_acc_adv_Rand_Aug_Batch</td><td>50</td></tr><tr><td>test_acc_adv_Worst_Of_100</td><td>64.67</td></tr><tr><td>test_clean_acc</td><td>77.83</td></tr><tr><td>test_loss_adv_Fo_Adam</td><td>2.16656</td></tr><tr><td>test_loss_adv_Fo_PGD</td><td>1.58418</td></tr><tr><td>test_loss_adv_Gaussian_Batch</td><td>2.12473</td></tr><tr><td>test_loss_adv_LMC_Laplacian_Linf</td><td>1.57986</td></tr><tr><td>test_loss_adv_Laplacian_Batch</td><td>2.11561</td></tr><tr><td>test_loss_adv_Rand_Aug_Batch</td><td>2.31001</td></tr><tr><td>test_loss_adv_Worst_Of_100</td><td>1.4346</td></tr><tr><td>test_loss_adv_mean_Fo_Adam</td><td>2.16656</td></tr><tr><td>test_loss_adv_mean_Fo_PGD</td><td>1.58418</td></tr><tr><td>test_loss_adv_mean_Gaussian_Batch</td><td>1.5199</td></tr><tr><td>test_loss_adv_mean_LMC_Laplacian_Linf</td><td>1.57986</td></tr><tr><td>test_loss_adv_mean_Laplacian_Batch</td><td>1.46871</td></tr><tr><td>test_loss_adv_mean_Rand_Aug_Batch</td><td>1.45649</td></tr><tr><td>test_loss_adv_mean_Worst_Of_100</td><td>1.4346</td></tr><tr><td>train_acc_adv_Fo_Adam</td><td>90</td></tr><tr><td>train_acc_adv_Fo_PGD</td><td>90</td></tr><tr><td>train_acc_adv_Gaussian_Batch</td><td>100</td></tr><tr><td>train_acc_adv_LMC_Laplacian_Linf</td><td>100</td></tr><tr><td>train_acc_adv_Laplacian_Batch</td><td>100</td></tr><tr><td>train_acc_adv_Rand_Aug_Batch</td><td>100</td></tr><tr><td>train_acc_adv_Worst_Of_100</td><td>92.8</td></tr><tr><td>train_clean_acc</td><td>99.8</td></tr><tr><td>train_loss_adv_Fo_Adam</td><td>0.4769</td></tr><tr><td>train_loss_adv_Fo_PGD</td><td>0.44763</td></tr><tr><td>train_loss_adv_Gaussian_Batch</td><td>0.00423</td></tr><tr><td>train_loss_adv_LMC_Laplacian_Linf</td><td>0.46065</td></tr><tr><td>train_loss_adv_Laplacian_Batch</td><td>0.00496</td></tr><tr><td>train_loss_adv_Rand_Aug_Batch</td><td>0.00843</td></tr><tr><td>train_loss_adv_Worst_Of_100</td><td>0.44203</td></tr><tr><td>train_loss_adv_mean_Fo_Adam</td><td>2.16656</td></tr><tr><td>train_loss_adv_mean_Fo_PGD</td><td>1.58418</td></tr><tr><td>train_loss_adv_mean_Gaussian_Batch</td><td>1.5199</td></tr><tr><td>train_loss_adv_mean_LMC_Laplacian_Linf</td><td>1.57986</td></tr><tr><td>train_loss_adv_mean_Laplacian_Batch</td><td>1.46871</td></tr><tr><td>train_loss_adv_mean_Rand_Aug_Batch</td><td>1.45649</td></tr><tr><td>train_loss_adv_mean_Worst_Of_100</td><td>1.4346</td></tr><tr><td>tx</td><td>3</td></tr><tr><td>ty</td><td>3</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">SE Gaussian wrn-28-10 0</strong>: <a href=\"https://wandb.ai/hounie/DAug-CIFAR100/runs/3mt3jee1\" target=\"_blank\">https://wandb.ai/hounie/DAug-CIFAR100/runs/3mt3jee1</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220523_155135-3mt3jee1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR100 SE\n",
      "Files already downloaded and verified\n",
      "5000\n",
      "model wrn-28-10\n",
      "Using WRN-28-10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/chiche/advbench/notebooks/wandb/run-20220523_160659-omtaia44</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"https://wandb.ai/hounie/DAug-CIFAR100/runs/omtaia44\" target=\"_blank\">SE Laplacian wrn-28-10 0</a></strong> to <a href=\"https://wandb.ai/hounie/DAug-CIFAR100\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [10:15,  1.62it/s]\n",
      "500it [05:07,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Worst_Of_100...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_acc_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>test_loss_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>test_loss_adv_mean_Worst_Of_100</td><td>▁</td></tr><tr><td>train_acc_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>train_loss_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>train_loss_adv_mean_Worst_Of_100</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>loss_avg</td><td>0.01082</td></tr><tr><td>lr</td><td>0.0008</td></tr><tr><td>mean_test_acc_advFo_Adam</td><td>30</td></tr><tr><td>mean_test_acc_advFo_PGD</td><td>50</td></tr><tr><td>mean_test_acc_advGaussian_Batch</td><td>60</td></tr><tr><td>mean_test_acc_advLMC_Laplacian_Linf</td><td>40</td></tr><tr><td>mean_test_acc_advLaplacian_Batch</td><td>61</td></tr><tr><td>mean_test_acc_advRand_Aug_Batch</td><td>50</td></tr><tr><td>mean_train_acc_advFo_Adam</td><td>100</td></tr><tr><td>mean_train_acc_advFo_PGD</td><td>100</td></tr><tr><td>mean_train_acc_advGaussian_Batch</td><td>100</td></tr><tr><td>mean_train_acc_advLMC_Laplacian_Linf</td><td>100</td></tr><tr><td>mean_train_acc_advLaplacian_Batch</td><td>100</td></tr><tr><td>mean_train_acc_advRand_Aug_Batch</td><td>100</td></tr><tr><td>step</td><td>10000000</td></tr><tr><td>test_acc_adv_Fo_Adam</td><td>30</td></tr><tr><td>test_acc_adv_Fo_PGD</td><td>50</td></tr><tr><td>test_acc_adv_Gaussian_Batch</td><td>40</td></tr><tr><td>test_acc_adv_LMC_Laplacian_Linf</td><td>40</td></tr><tr><td>test_acc_adv_Laplacian_Batch</td><td>40</td></tr><tr><td>test_acc_adv_Rand_Aug_Batch</td><td>20</td></tr><tr><td>test_acc_adv_Worst_Of_100</td><td>64.19</td></tr><tr><td>test_clean_acc</td><td>78.42</td></tr><tr><td>test_loss_adv_Fo_Adam</td><td>2.52787</td></tr><tr><td>test_loss_adv_Fo_PGD</td><td>2.04833</td></tr><tr><td>test_loss_adv_Gaussian_Batch</td><td>2.35704</td></tr><tr><td>test_loss_adv_LMC_Laplacian_Linf</td><td>1.81206</td></tr><tr><td>test_loss_adv_Laplacian_Batch</td><td>2.19039</td></tr><tr><td>test_loss_adv_Rand_Aug_Batch</td><td>2.96104</td></tr><tr><td>test_loss_adv_Worst_Of_100</td><td>1.4686</td></tr><tr><td>test_loss_adv_mean_Fo_Adam</td><td>2.52787</td></tr><tr><td>test_loss_adv_mean_Fo_PGD</td><td>2.04833</td></tr><tr><td>test_loss_adv_mean_Gaussian_Batch</td><td>1.3414</td></tr><tr><td>test_loss_adv_mean_LMC_Laplacian_Linf</td><td>1.81206</td></tr><tr><td>test_loss_adv_mean_Laplacian_Batch</td><td>1.40242</td></tr><tr><td>test_loss_adv_mean_Rand_Aug_Batch</td><td>1.82662</td></tr><tr><td>test_loss_adv_mean_Worst_Of_100</td><td>1.4686</td></tr><tr><td>train_acc_adv_Fo_Adam</td><td>100</td></tr><tr><td>train_acc_adv_Fo_PGD</td><td>100</td></tr><tr><td>train_acc_adv_Gaussian_Batch</td><td>100</td></tr><tr><td>train_acc_adv_LMC_Laplacian_Linf</td><td>100</td></tr><tr><td>train_acc_adv_Laplacian_Batch</td><td>100</td></tr><tr><td>train_acc_adv_Rand_Aug_Batch</td><td>100</td></tr><tr><td>train_acc_adv_Worst_Of_100</td><td>91.84</td></tr><tr><td>train_clean_acc</td><td>99.92</td></tr><tr><td>train_loss_adv_Fo_Adam</td><td>0.30094</td></tr><tr><td>train_loss_adv_Fo_PGD</td><td>0.27881</td></tr><tr><td>train_loss_adv_Gaussian_Batch</td><td>0.00387</td></tr><tr><td>train_loss_adv_LMC_Laplacian_Linf</td><td>0.21258</td></tr><tr><td>train_loss_adv_Laplacian_Batch</td><td>0.00496</td></tr><tr><td>train_loss_adv_Rand_Aug_Batch</td><td>0.00541</td></tr><tr><td>train_loss_adv_Worst_Of_100</td><td>0.49384</td></tr><tr><td>train_loss_adv_mean_Fo_Adam</td><td>2.52787</td></tr><tr><td>train_loss_adv_mean_Fo_PGD</td><td>2.04833</td></tr><tr><td>train_loss_adv_mean_Gaussian_Batch</td><td>1.3414</td></tr><tr><td>train_loss_adv_mean_LMC_Laplacian_Linf</td><td>1.81206</td></tr><tr><td>train_loss_adv_mean_Laplacian_Batch</td><td>1.40242</td></tr><tr><td>train_loss_adv_mean_Rand_Aug_Batch</td><td>1.82662</td></tr><tr><td>train_loss_adv_mean_Worst_Of_100</td><td>1.4686</td></tr><tr><td>tx</td><td>3</td></tr><tr><td>ty</td><td>3</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">SE Laplacian wrn-28-10 0</strong>: <a href=\"https://wandb.ai/hounie/DAug-CIFAR100/runs/omtaia44\" target=\"_blank\">https://wandb.ai/hounie/DAug-CIFAR100/runs/omtaia44</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220523_160659-omtaia44/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR100 SE\n",
      "Files already downloaded and verified\n",
      "5000\n",
      "model wrn-28-10\n",
      "Using WRN-28-10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/chiche/advbench/notebooks/wandb/run-20220523_162230-21dohc1p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"https://wandb.ai/hounie/DAug-CIFAR100/runs/21dohc1p\" target=\"_blank\">SE MH_DALE_PD_Reverse wrn-28-10 3</a></strong> to <a href=\"https://wandb.ai/hounie/DAug-CIFAR100\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [10:16,  1.62it/s]\n",
      "500it [05:08,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Worst_Of_100...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_acc_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>test_loss_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>test_loss_adv_mean_Worst_Of_100</td><td>▁</td></tr><tr><td>train_acc_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>train_loss_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>train_loss_adv_mean_Worst_Of_100</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acceptance rate_avg</td><td>0.91253</td></tr><tr><td>clean loss_avg</td><td>0.00204</td></tr><tr><td>delta L1-border_avg</td><td>-3.984</td></tr><tr><td>dual variable_avg</td><td>2.23259</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>loss_avg</td><td>0.01589</td></tr><tr><td>lr</td><td>0.0008</td></tr><tr><td>mean_test_acc_advFo_Adam</td><td>50</td></tr><tr><td>mean_test_acc_advFo_PGD</td><td>50</td></tr><tr><td>mean_test_acc_advGaussian_Batch</td><td>67</td></tr><tr><td>mean_test_acc_advLaplacian_Batch</td><td>69</td></tr><tr><td>mean_test_acc_advRand_Aug_Batch</td><td>56</td></tr><tr><td>mean_train_acc_advFo_Adam</td><td>100</td></tr><tr><td>mean_train_acc_advFo_PGD</td><td>100</td></tr><tr><td>mean_train_acc_advGaussian_Batch</td><td>100</td></tr><tr><td>mean_train_acc_advLaplacian_Batch</td><td>100</td></tr><tr><td>mean_train_acc_advRand_Aug_Batch</td><td>100</td></tr><tr><td>robust loss_avg</td><td>0.00621</td></tr><tr><td>step</td><td>10000000</td></tr><tr><td>test_acc_adv_Fo_Adam</td><td>50</td></tr><tr><td>test_acc_adv_Fo_PGD</td><td>50</td></tr><tr><td>test_acc_adv_Gaussian_Batch</td><td>30</td></tr><tr><td>test_acc_adv_Laplacian_Batch</td><td>30</td></tr><tr><td>test_acc_adv_Rand_Aug_Batch</td><td>20</td></tr><tr><td>test_acc_adv_Worst_Of_100</td><td>65.11</td></tr><tr><td>test_clean_acc</td><td>79.89</td></tr><tr><td>test_loss_adv_Fo_Adam</td><td>1.92884</td></tr><tr><td>test_loss_adv_Fo_PGD</td><td>1.89826</td></tr><tr><td>test_loss_adv_Gaussian_Batch</td><td>1.92302</td></tr><tr><td>test_loss_adv_Laplacian_Batch</td><td>1.60493</td></tr><tr><td>test_loss_adv_Rand_Aug_Batch</td><td>2.64105</td></tr><tr><td>test_loss_adv_Worst_Of_100</td><td>1.40746</td></tr><tr><td>test_loss_adv_mean_Fo_Adam</td><td>1.92884</td></tr><tr><td>test_loss_adv_mean_Fo_PGD</td><td>1.89826</td></tr><tr><td>test_loss_adv_mean_Gaussian_Batch</td><td>0.92554</td></tr><tr><td>test_loss_adv_mean_Laplacian_Batch</td><td>0.81436</td></tr><tr><td>test_loss_adv_mean_Rand_Aug_Batch</td><td>1.40888</td></tr><tr><td>test_loss_adv_mean_Worst_Of_100</td><td>1.40746</td></tr><tr><td>train_acc_adv_Fo_Adam</td><td>100</td></tr><tr><td>train_acc_adv_Fo_PGD</td><td>100</td></tr><tr><td>train_acc_adv_Gaussian_Batch</td><td>100</td></tr><tr><td>train_acc_adv_Laplacian_Batch</td><td>100</td></tr><tr><td>train_acc_adv_Rand_Aug_Batch</td><td>100</td></tr><tr><td>train_acc_adv_Worst_Of_100</td><td>93.34</td></tr><tr><td>train_clean_acc</td><td>100</td></tr><tr><td>train_loss_adv_Fo_Adam</td><td>0.22016</td></tr><tr><td>train_loss_adv_Fo_PGD</td><td>0.29499</td></tr><tr><td>train_loss_adv_Gaussian_Batch</td><td>0.05972</td></tr><tr><td>train_loss_adv_Laplacian_Batch</td><td>0.00489</td></tr><tr><td>train_loss_adv_Rand_Aug_Batch</td><td>0.02909</td></tr><tr><td>train_loss_adv_Worst_Of_100</td><td>0.29971</td></tr><tr><td>train_loss_adv_mean_Fo_Adam</td><td>1.92884</td></tr><tr><td>train_loss_adv_mean_Fo_PGD</td><td>1.89826</td></tr><tr><td>train_loss_adv_mean_Gaussian_Batch</td><td>0.92554</td></tr><tr><td>train_loss_adv_mean_Laplacian_Batch</td><td>0.81436</td></tr><tr><td>train_loss_adv_mean_Rand_Aug_Batch</td><td>1.40888</td></tr><tr><td>train_loss_adv_mean_Worst_Of_100</td><td>1.40746</td></tr><tr><td>tx</td><td>3</td></tr><tr><td>ty</td><td>3</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">SE MH_DALE_PD_Reverse wrn-28-10 3</strong>: <a href=\"https://wandb.ai/hounie/DAug-CIFAR100/runs/21dohc1p\" target=\"_blank\">https://wandb.ai/hounie/DAug-CIFAR100/runs/21dohc1p</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220523_162230-21dohc1p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR100 SE\n",
      "Files already downloaded and verified\n",
      "5000\n",
      "model wrn-28-10\n",
      "Using WRN-28-10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/chiche/advbench/notebooks/wandb/run-20220523_163803-2ga4la19</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"https://wandb.ai/hounie/DAug-CIFAR100/runs/2ga4la19\" target=\"_blank\">SE Adversarial_Adam wrn-28-10 1</a></strong> to <a href=\"https://wandb.ai/hounie/DAug-CIFAR100\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [10:19,  1.61it/s]\n",
      "500it [05:08,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Worst_Of_100...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_acc_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>test_loss_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>test_loss_adv_mean_Worst_Of_100</td><td>▁</td></tr><tr><td>train_acc_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>train_loss_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>train_loss_adv_mean_Worst_Of_100</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>loss_avg</td><td>0.01104</td></tr><tr><td>lr</td><td>0.0008</td></tr><tr><td>mean_test_acc_advFo_Adam</td><td>40</td></tr><tr><td>mean_test_acc_advFo_PGD</td><td>60</td></tr><tr><td>mean_test_acc_advGaussian_Batch</td><td>66</td></tr><tr><td>mean_test_acc_advLaplacian_Batch</td><td>65</td></tr><tr><td>mean_test_acc_advRand_Aug_Batch</td><td>65</td></tr><tr><td>mean_train_acc_advFo_Adam</td><td>100</td></tr><tr><td>mean_train_acc_advFo_PGD</td><td>100</td></tr><tr><td>mean_train_acc_advGaussian_Batch</td><td>100</td></tr><tr><td>mean_train_acc_advLaplacian_Batch</td><td>100</td></tr><tr><td>mean_train_acc_advRand_Aug_Batch</td><td>100</td></tr><tr><td>step</td><td>10000000</td></tr><tr><td>test_acc_adv_Fo_Adam</td><td>40</td></tr><tr><td>test_acc_adv_Fo_PGD</td><td>60</td></tr><tr><td>test_acc_adv_Gaussian_Batch</td><td>50</td></tr><tr><td>test_acc_adv_Laplacian_Batch</td><td>50</td></tr><tr><td>test_acc_adv_Rand_Aug_Batch</td><td>40</td></tr><tr><td>test_acc_adv_Worst_Of_100</td><td>66.32</td></tr><tr><td>test_clean_acc</td><td>76.97</td></tr><tr><td>test_loss_adv_Fo_Adam</td><td>2.25221</td></tr><tr><td>test_loss_adv_Fo_PGD</td><td>1.82679</td></tr><tr><td>test_loss_adv_Gaussian_Batch</td><td>2.65771</td></tr><tr><td>test_loss_adv_Laplacian_Batch</td><td>2.34178</td></tr><tr><td>test_loss_adv_Rand_Aug_Batch</td><td>2.58797</td></tr><tr><td>test_loss_adv_Worst_Of_100</td><td>1.35404</td></tr><tr><td>test_loss_adv_mean_Fo_Adam</td><td>2.25221</td></tr><tr><td>test_loss_adv_mean_Fo_PGD</td><td>1.82679</td></tr><tr><td>test_loss_adv_mean_Gaussian_Batch</td><td>1.40771</td></tr><tr><td>test_loss_adv_mean_Laplacian_Batch</td><td>1.53621</td></tr><tr><td>test_loss_adv_mean_Rand_Aug_Batch</td><td>1.49496</td></tr><tr><td>test_loss_adv_mean_Worst_Of_100</td><td>1.35404</td></tr><tr><td>train_acc_adv_Fo_Adam</td><td>100</td></tr><tr><td>train_acc_adv_Fo_PGD</td><td>100</td></tr><tr><td>train_acc_adv_Gaussian_Batch</td><td>100</td></tr><tr><td>train_acc_adv_Laplacian_Batch</td><td>100</td></tr><tr><td>train_acc_adv_Rand_Aug_Batch</td><td>100</td></tr><tr><td>train_acc_adv_Worst_Of_100</td><td>94.58</td></tr><tr><td>train_clean_acc</td><td>99.66</td></tr><tr><td>train_loss_adv_Fo_Adam</td><td>0.20548</td></tr><tr><td>train_loss_adv_Fo_PGD</td><td>0.1945</td></tr><tr><td>train_loss_adv_Gaussian_Batch</td><td>0.00573</td></tr><tr><td>train_loss_adv_Laplacian_Batch</td><td>0.00998</td></tr><tr><td>train_loss_adv_Rand_Aug_Batch</td><td>0.00599</td></tr><tr><td>train_loss_adv_Worst_Of_100</td><td>0.37132</td></tr><tr><td>train_loss_adv_mean_Fo_Adam</td><td>2.25221</td></tr><tr><td>train_loss_adv_mean_Fo_PGD</td><td>1.82679</td></tr><tr><td>train_loss_adv_mean_Gaussian_Batch</td><td>1.40771</td></tr><tr><td>train_loss_adv_mean_Laplacian_Batch</td><td>1.53621</td></tr><tr><td>train_loss_adv_mean_Rand_Aug_Batch</td><td>1.49496</td></tr><tr><td>train_loss_adv_mean_Worst_Of_100</td><td>1.35404</td></tr><tr><td>tx</td><td>3</td></tr><tr><td>ty</td><td>3</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">SE Adversarial_Adam wrn-28-10 1</strong>: <a href=\"https://wandb.ai/hounie/DAug-CIFAR100/runs/2ga4la19\" target=\"_blank\">https://wandb.ai/hounie/DAug-CIFAR100/runs/2ga4la19</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220523_163803-2ga4la19/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR100 SE\n",
      "Files already downloaded and verified\n",
      "5000\n",
      "model wrn-28-10\n",
      "Using WRN-28-10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/chiche/advbench/notebooks/wandb/run-20220523_165337-3m8flyqh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"https://wandb.ai/hounie/DAug-CIFAR100/runs/3m8flyqh\" target=\"_blank\">SE Laplacian_DALE_PD_Reverse wrn-28-10 3</a></strong> to <a href=\"https://wandb.ai/hounie/DAug-CIFAR100\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [10:15,  1.62it/s]\n",
      "500it [05:08,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Worst_Of_100...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_acc_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>test_loss_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>test_loss_adv_mean_Worst_Of_100</td><td>▁</td></tr><tr><td>train_acc_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>train_loss_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>train_loss_adv_mean_Worst_Of_100</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>clean loss_avg</td><td>0.00207</td></tr><tr><td>delta L1-border_avg</td><td>-2.4888</td></tr><tr><td>dual variable_avg</td><td>1.86173</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>loss_avg</td><td>0.0139</td></tr><tr><td>lr</td><td>0.0008</td></tr><tr><td>mean_test_acc_advFo_Adam</td><td>70</td></tr><tr><td>mean_test_acc_advFo_PGD</td><td>70</td></tr><tr><td>mean_test_acc_advGaussian_Batch</td><td>70</td></tr><tr><td>mean_test_acc_advLMC_Laplacian_Linf</td><td>0</td></tr><tr><td>mean_test_acc_advLaplacian_Batch</td><td>71</td></tr><tr><td>mean_test_acc_advRand_Aug_Batch</td><td>56</td></tr><tr><td>mean_train_acc_advFo_Adam</td><td>100</td></tr><tr><td>mean_train_acc_advFo_PGD</td><td>100</td></tr><tr><td>mean_train_acc_advGaussian_Batch</td><td>100</td></tr><tr><td>mean_train_acc_advLMC_Laplacian_Linf</td><td>0</td></tr><tr><td>mean_train_acc_advLaplacian_Batch</td><td>100</td></tr><tr><td>mean_train_acc_advRand_Aug_Batch</td><td>100</td></tr><tr><td>robust loss_avg</td><td>0.00635</td></tr><tr><td>step</td><td>10000000</td></tr><tr><td>test_acc_adv_Fo_Adam</td><td>70</td></tr><tr><td>test_acc_adv_Fo_PGD</td><td>70</td></tr><tr><td>test_acc_adv_Gaussian_Batch</td><td>60</td></tr><tr><td>test_acc_adv_LMC_Laplacian_Linf</td><td>0</td></tr><tr><td>test_acc_adv_Laplacian_Batch</td><td>60</td></tr><tr><td>test_acc_adv_Rand_Aug_Batch</td><td>30</td></tr><tr><td>test_acc_adv_Worst_Of_100</td><td>67.31</td></tr><tr><td>test_clean_acc</td><td>79.96</td></tr><tr><td>test_loss_adv_Fo_Adam</td><td>1.8586</td></tr><tr><td>test_loss_adv_Fo_PGD</td><td>1.22602</td></tr><tr><td>test_loss_adv_Gaussian_Batch</td><td>1.91354</td></tr><tr><td>test_loss_adv_LMC_Laplacian_Linf</td><td>4.60275</td></tr><tr><td>test_loss_adv_Laplacian_Batch</td><td>1.4974</td></tr><tr><td>test_loss_adv_Rand_Aug_Batch</td><td>2.27183</td></tr><tr><td>test_loss_adv_Worst_Of_100</td><td>1.31131</td></tr><tr><td>test_loss_adv_mean_Fo_Adam</td><td>1.8586</td></tr><tr><td>test_loss_adv_mean_Fo_PGD</td><td>1.22602</td></tr><tr><td>test_loss_adv_mean_Gaussian_Batch</td><td>1.09189</td></tr><tr><td>test_loss_adv_mean_LMC_Laplacian_Linf</td><td>4.60275</td></tr><tr><td>test_loss_adv_mean_Laplacian_Batch</td><td>0.84884</td></tr><tr><td>test_loss_adv_mean_Rand_Aug_Batch</td><td>1.43087</td></tr><tr><td>test_loss_adv_mean_Worst_Of_100</td><td>1.31131</td></tr><tr><td>train_acc_adv_Fo_Adam</td><td>100</td></tr><tr><td>train_acc_adv_Fo_PGD</td><td>100</td></tr><tr><td>train_acc_adv_Gaussian_Batch</td><td>100</td></tr><tr><td>train_acc_adv_LMC_Laplacian_Linf</td><td>0</td></tr><tr><td>train_acc_adv_Laplacian_Batch</td><td>100</td></tr><tr><td>train_acc_adv_Rand_Aug_Batch</td><td>100</td></tr><tr><td>train_acc_adv_Worst_Of_100</td><td>95.6</td></tr><tr><td>train_clean_acc</td><td>100</td></tr><tr><td>train_clean_acc_nb</td><td>0.98</td></tr><tr><td>train_clean_loss_nb</td><td>5.45892</td></tr><tr><td>train_loss_adv_Fo_Adam</td><td>0.12537</td></tr><tr><td>train_loss_adv_Fo_PGD</td><td>0.16951</td></tr><tr><td>train_loss_adv_Gaussian_Batch</td><td>0.00951</td></tr><tr><td>train_loss_adv_LMC_Laplacian_Linf</td><td>4.63484</td></tr><tr><td>train_loss_adv_Laplacian_Batch</td><td>0.00224</td></tr><tr><td>train_loss_adv_Rand_Aug_Batch</td><td>0.0281</td></tr><tr><td>train_loss_adv_Worst_Of_100</td><td>0.23555</td></tr><tr><td>train_loss_adv_mean_Fo_Adam</td><td>1.8586</td></tr><tr><td>train_loss_adv_mean_Fo_PGD</td><td>1.22602</td></tr><tr><td>train_loss_adv_mean_Gaussian_Batch</td><td>1.09189</td></tr><tr><td>train_loss_adv_mean_LMC_Laplacian_Linf</td><td>4.60275</td></tr><tr><td>train_loss_adv_mean_Laplacian_Batch</td><td>0.84884</td></tr><tr><td>train_loss_adv_mean_Rand_Aug_Batch</td><td>1.43087</td></tr><tr><td>train_loss_adv_mean_Worst_Of_100</td><td>1.31131</td></tr><tr><td>tx</td><td>3</td></tr><tr><td>ty</td><td>3</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">SE Laplacian_DALE_PD_Reverse wrn-28-10 3</strong>: <a href=\"https://wandb.ai/hounie/DAug-CIFAR100/runs/3m8flyqh\" target=\"_blank\">https://wandb.ai/hounie/DAug-CIFAR100/runs/3m8flyqh</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220523_165337-3m8flyqh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR100 SE\n",
      "Files already downloaded and verified\n",
      "5000\n",
      "model wrn-28-10\n",
      "Using WRN-28-10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/chiche/advbench/notebooks/wandb/run-20220523_170909-37l0obro</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"https://wandb.ai/hounie/DAug-CIFAR100/runs/37l0obro\" target=\"_blank\">SE Augmentation wrn-28-10 3</a></strong> to <a href=\"https://wandb.ai/hounie/DAug-CIFAR100\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [10:15,  1.63it/s]\n",
      "500it [05:07,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Worst_Of_100...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_acc_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>test_loss_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>test_loss_adv_mean_Worst_Of_100</td><td>▁</td></tr><tr><td>train_acc_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>train_loss_adv_Worst_Of_100</td><td>▁</td></tr><tr><td>train_loss_adv_mean_Worst_Of_100</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>loss_avg</td><td>0.12976</td></tr><tr><td>lr</td><td>0.0008</td></tr><tr><td>mean_test_acc_advFo_Adam</td><td>20</td></tr><tr><td>mean_test_acc_advFo_PGD</td><td>50</td></tr><tr><td>mean_test_acc_advGaussian_Batch</td><td>59</td></tr><tr><td>mean_test_acc_advLMC_Laplacian_Linf</td><td>0</td></tr><tr><td>mean_test_acc_advLaplacian_Batch</td><td>58</td></tr><tr><td>mean_test_acc_advRand_Aug_Batch</td><td>62</td></tr><tr><td>mean_train_acc_advFo_Adam</td><td>70</td></tr><tr><td>mean_train_acc_advFo_PGD</td><td>60</td></tr><tr><td>mean_train_acc_advGaussian_Batch</td><td>99</td></tr><tr><td>mean_train_acc_advLMC_Laplacian_Linf</td><td>0</td></tr><tr><td>mean_train_acc_advLaplacian_Batch</td><td>98</td></tr><tr><td>mean_train_acc_advRand_Aug_Batch</td><td>99</td></tr><tr><td>step</td><td>10000000</td></tr><tr><td>test_acc_adv_Fo_Adam</td><td>20</td></tr><tr><td>test_acc_adv_Fo_PGD</td><td>50</td></tr><tr><td>test_acc_adv_Gaussian_Batch</td><td>20</td></tr><tr><td>test_acc_adv_LMC_Laplacian_Linf</td><td>0</td></tr><tr><td>test_acc_adv_Laplacian_Batch</td><td>20</td></tr><tr><td>test_acc_adv_Rand_Aug_Batch</td><td>30</td></tr><tr><td>test_acc_adv_Worst_Of_100</td><td>61.89</td></tr><tr><td>test_clean_acc</td><td>76.25</td></tr><tr><td>test_loss_adv_Fo_Adam</td><td>3.02971</td></tr><tr><td>test_loss_adv_Fo_PGD</td><td>1.97543</td></tr><tr><td>test_loss_adv_Gaussian_Batch</td><td>2.52741</td></tr><tr><td>test_loss_adv_LMC_Laplacian_Linf</td><td>4.65932</td></tr><tr><td>test_loss_adv_Laplacian_Batch</td><td>2.5675</td></tr><tr><td>test_loss_adv_Rand_Aug_Batch</td><td>2.3009</td></tr><tr><td>test_loss_adv_Worst_Of_100</td><td>1.50309</td></tr><tr><td>test_loss_adv_mean_Fo_Adam</td><td>3.02971</td></tr><tr><td>test_loss_adv_mean_Fo_PGD</td><td>1.97543</td></tr><tr><td>test_loss_adv_mean_Gaussian_Batch</td><td>1.35577</td></tr><tr><td>test_loss_adv_mean_LMC_Laplacian_Linf</td><td>4.65932</td></tr><tr><td>test_loss_adv_mean_Laplacian_Batch</td><td>1.39825</td></tr><tr><td>test_loss_adv_mean_Rand_Aug_Batch</td><td>1.18077</td></tr><tr><td>test_loss_adv_mean_Worst_Of_100</td><td>1.50309</td></tr><tr><td>train_acc_adv_Fo_Adam</td><td>70</td></tr><tr><td>train_acc_adv_Fo_PGD</td><td>60</td></tr><tr><td>train_acc_adv_Gaussian_Batch</td><td>90</td></tr><tr><td>train_acc_adv_LMC_Laplacian_Linf</td><td>0</td></tr><tr><td>train_acc_adv_Laplacian_Batch</td><td>90</td></tr><tr><td>train_acc_adv_Rand_Aug_Batch</td><td>90</td></tr><tr><td>train_acc_adv_Worst_Of_100</td><td>86.66</td></tr><tr><td>train_clean_acc</td><td>99.86</td></tr><tr><td>train_clean_acc_nb</td><td>0.96</td></tr><tr><td>train_clean_loss_nb</td><td>5.30692</td></tr><tr><td>train_loss_adv_Fo_Adam</td><td>0.94059</td></tr><tr><td>train_loss_adv_Fo_PGD</td><td>0.8528</td></tr><tr><td>train_loss_adv_Gaussian_Batch</td><td>0.10472</td></tr><tr><td>train_loss_adv_LMC_Laplacian_Linf</td><td>4.55833</td></tr><tr><td>train_loss_adv_Laplacian_Batch</td><td>0.25969</td></tr><tr><td>train_loss_adv_Rand_Aug_Batch</td><td>0.27106</td></tr><tr><td>train_loss_adv_Worst_Of_100</td><td>0.5452</td></tr><tr><td>train_loss_adv_mean_Fo_Adam</td><td>3.02971</td></tr><tr><td>train_loss_adv_mean_Fo_PGD</td><td>1.97543</td></tr><tr><td>train_loss_adv_mean_Gaussian_Batch</td><td>1.35577</td></tr><tr><td>train_loss_adv_mean_LMC_Laplacian_Linf</td><td>4.65932</td></tr><tr><td>train_loss_adv_mean_Laplacian_Batch</td><td>1.39825</td></tr><tr><td>train_loss_adv_mean_Rand_Aug_Batch</td><td>1.18077</td></tr><tr><td>train_loss_adv_mean_Worst_Of_100</td><td>1.50309</td></tr><tr><td>tx</td><td>3</td></tr><tr><td>ty</td><td>3</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">SE Augmentation wrn-28-10 3</strong>: <a href=\"https://wandb.ai/hounie/DAug-CIFAR100/runs/37l0obro\" target=\"_blank\">https://wandb.ai/hounie/DAug-CIFAR100/runs/37l0obro</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220523_170909-37l0obro/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR100 SE\n",
      "Files already downloaded and verified\n",
      "5000\n",
      "model wrn-28-10\n",
      "Using WRN-28-10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/chiche/advbench/notebooks/wandb/run-20220523_172438-2tor8s5t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"https://wandb.ai/hounie/DAug-CIFAR100/runs/2tor8s5t\" target=\"_blank\">SE ERM wrn-28-10 3</a></strong> to <a href=\"https://wandb.ai/hounie/DAug-CIFAR100\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [10:16,  1.62it/s]\n",
      "500it [05:08,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Worst_Of_100...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "data_dir = '../advbench/data'\n",
    "device = \"cuda:1\"\n",
    "t_attacks = [\"Worst_Of_K\",]\n",
    "for exp_id in tqdm(df[\"id\"]):\n",
    "    if True:\n",
    "        api = wandb.Api(timeout=50)\n",
    "        exp = df[df[\"id\"]==exp_id]\n",
    "        dataset =  exp[\"dataset\"].values[0]\n",
    "        algorithm = \"ERM\"\n",
    "        perturbation = exp[\"perturbation\"].values[0]\n",
    "        model = exp[\"model\"].values[0]\n",
    "        if perturbation == \"SE\" and \"rot\" not in model:\n",
    "            project = f\"DAug-{dataset}\"\n",
    "            print(dataset, perturbation)\n",
    "            t_hparams = exp[test_keys].to_dict(orient='index')[exp.index.values[0]]\n",
    "            test_hparams = {}\n",
    "            for k, v in t_hparams.items():\n",
    "                test_hparams[k.replace(\"test_\",\"\")] = v\n",
    "\n",
    "            hparams = exp[train_keys].to_dict(orient='index')[exp.index.values[0]]\n",
    "            hparams['model'] = model\n",
    "            hparams['epsilon'] = torch.tensor([hparams[f'epsilon_{i}'] for i in (\"rot\",\"tx\",\"ty\")]).to(device)\n",
    "            test_hparams['epsilon'] = hparams['epsilon']\n",
    "            hparams['batched'] = False\n",
    "            test_hparams['batched'] = False\n",
    "            hparams['worst_of_k_steps'] =  100\n",
    "            test_hparams['worst_of_k_steps'] =  100\n",
    "            aug = hparams[\"augment\"]\n",
    "            dataset = vars(datasets)[dataset](data_dir, augmentation = aug)\n",
    "            train_ldr, val_ldr, test_ldr = datasets.to_loaders(dataset, hparams, device=device)\n",
    "            kw_args = {\"perturbation\": perturbation}\n",
    "            #algorithm = vars(algorithms)[algorithm](\n",
    "             #   dataset.INPUT_SHAPE, \n",
    "              #  dataset.NUM_CLASSES,\n",
    "               # hparams,\n",
    "                #device,\n",
    "                #**kw_args).to(device)\n",
    "            algorithm = load_weights(exp[\"weights\"].values[0], dataset, device=\"cuda:1\")\n",
    "\n",
    "            test_attacks = {\n",
    "                \"Worst_Of_100\": attacks.Worst_Of_K(algorithm.classifier, test_hparams, device, perturbation=\"SE\")}\n",
    "\n",
    "            #train_clean_acc, train_clean_loss = misc.accuracy_loss(algorithm, val_ldr, device)\n",
    "            #run = api.run(f\"hounie/{project}/{exp_id}\")\n",
    "            wandb.init(project=project, resume=exp_id)\n",
    "            #wandb.log({'train_clean_acc_nb': train_clean_acc, 'train_clean_loss_nb': train_clean_loss})\n",
    "            # compute save and log adversarial accuracies on validation/test sets\n",
    "            for attack_name, attack in test_attacks.items():\n",
    "                test_adv_acc, test_adv_acc_mean, adv_loss, accs, loss, deltas = misc.adv_accuracy_loss_delta(algorithm, test_ldr, device, attack)\n",
    "                train_adv_acc, train_adv_acc_mean, train_adv_loss, train_accs, train_loss, train_deltas = misc.adv_accuracy_loss_delta(algorithm, val_ldr, device, attack)\n",
    "                print(f\"Logging {attack_name}...\")\n",
    "                wandb.log({'test_acc_adv_'+attack_name: test_adv_acc, 'test_loss_adv_'+attack_name: adv_loss,\n",
    "                'test_loss_adv_mean_'+attack_name: loss.mean()})\n",
    "                wandb.log({'train_acc_adv_'+attack_name: train_adv_acc,'train_loss_adv_'+attack_name: train_adv_loss,\n",
    "                'train_loss_adv_mean_'+attack_name: loss.mean()})\n",
    "            wandb.finish(quiet=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65f58aa27a38851e3e9850fef15fa7db5088b1b5f537a1afba292c768d907c52"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
