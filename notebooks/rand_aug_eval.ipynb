{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import matplotlib.colors as mcolors\n",
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from advbench.datasets import MNIST, STL10\n",
    "from advbench.datasets import to_loaders\n",
    "from advbench.algorithms import ERM, Augmentation, Adversarial_Worst_Of_K, Adversarial_PGD\n",
    "from advbench.attacks import Fo_Adam\n",
    "from advbench import hparams_registry\n",
    "from advbench.lib import  misc\n",
    "import torch\n",
    "from advbench.lib.transformations import se_matrix, angle_to_rotation_matrix, se_transform\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as tt\n",
    "import tarfile\n",
    "from torch import nn\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from advbench.scripts.train import PD_ALGORITHMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import matplotlib.colors as mcolors\n",
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from advbench.datasets import to_loaders\n",
    "from advbench.algorithms import ERM, Augmentation, Adversarial_Worst_Of_K, Adversarial_PGD\n",
    "from advbench.attacks import Fo_Adam\n",
    "from advbench import hparams_registry\n",
    "from advbench.lib import  misc\n",
    "import torch\n",
    "from advbench.lib.transformations import se_matrix, angle_to_rotation_matrix, se_transform\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from humanfriendly import format_timespan\n",
    "\n",
    "\n",
    "from advbench import datasets\n",
    "from advbench import algorithms\n",
    "from advbench import attacks\n",
    "from advbench import hparams_registry\n",
    "from advbench.lib import misc, meters, plotting, logging\n",
    "from torch.cuda.amp import autocast\n",
    "from torchsummary import summary\n",
    "DEVICE = \"cuda\"\n",
    "DOWNLOAD_WEIGHTS = False\n",
    "PULL_METRICS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(weight_path, dataset, device=DEVICE, hparams={}):       \n",
    "        kw_args = {\"perturbation\": hparams[\"perturbation\"]}\n",
    "        if hparams[\"algorithm\"] in PD_ALGORITHMS: \n",
    "            if hparams[\"algorithm\"].endswith(\"Reverse\"):\n",
    "                kw_args[\"init\"] = 0.0\n",
    "            else:\n",
    "                kw_args[\"init\"] = 1.0\n",
    "        print(hparams[\"perturbation\"])\n",
    "        algorithm = vars(algorithms)[hparams[\"algorithm\"]](\n",
    "        dataset.INPUT_SHAPE, \n",
    "        dataset.NUM_CLASSES,\n",
    "        hparams,\n",
    "        device,\n",
    "        **kw_args).to(device)\n",
    "        w_dict = torch.load(weight_path,map_location=DEVICE)\n",
    "        #print(weight_dict.keys())\n",
    "        #if db==\"mnist\":\n",
    "        weight_dict = {}\n",
    "        for s,v in w_dict.items():\n",
    "                if \"classifier\" in s and \"model\" not in s:\n",
    "                        weight_dict[s.replace('classifier', 'classifier.model')] = v\n",
    "                else:\n",
    "                        weight_dict[s] = v \n",
    "        algorithm.load_state_dict(weight_dict)\n",
    "        return algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PULL_METRICS:\n",
    "    api = wandb.Api(timeout=50)\n",
    "    dsets = [\"modelnet40\"]#[\"STL10\", \"CIFAR100\"]\n",
    "    #results_dfs = {}\n",
    "    entity = \"hounie\"\n",
    "    all_runs_list = []\n",
    "    for dataset in dsets:\n",
    "        print(\"Fetching data for {}\".format(dataset))\n",
    "        project = f\"OOD-{dataset}\"\n",
    "        base = f\"../trained_weights/{project}\"\n",
    "        Path( base ).mkdir( parents=True, exist_ok=True )\n",
    "        runs = api.runs(f\"{entity}/{project}\")\n",
    "        print(f\"{len(runs)} runs found\")\n",
    "        for run in tqdm(runs):\n",
    "            if run.state == \"finished\" or (dataset==\"modelnet40\" and run.state != \"running\"):\n",
    "                id = run.id\n",
    "                run = api.run(f\"{entity}/{project}/{id}\")\n",
    "                tmp_path = os.path.join(base, f\"tmp\")\n",
    "                weight_dir = os.path.join(base, run.name)\n",
    "                path = os.path.join(weight_dir, f\"{run.id}.pkl\")\n",
    "                Path( weight_dir ).mkdir( parents=True, exist_ok=True )\n",
    "                results = {**run.summary, **run.config, \"weights\": path, \"id\": run.id, \"name\":run.name}\n",
    "                if DOWNLOAD_WEIGHTS:\n",
    "                    try:\n",
    "                        print(f\"train-output/{run.name[:-4]} DGCNN {run.name[-1]}_ckpt.pkl\")\n",
    "                        f = run.file(f\"train-output/{run.name[:-4]} DGCNN {run.name[-1]}_ckpt.pkl\").download(tmp_path, replace=True) \n",
    "                        os.rename(f.name, path)\n",
    "                        all_runs_list.append(results)\n",
    "                    except:\n",
    "                        print(f\"{run.name} {run.id} failed\")\n",
    "                        \n",
    "    df = pd.DataFrame(all_runs_list)\n",
    "    df.to_csv(f\"./results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./results.csv\")\n",
    "test_keys = []\n",
    "train_keys = []\n",
    "for c in df.columns:\n",
    "        if \"loss\" not in c and \"acc\" not in c:\n",
    "            if c.startswith(\"test\"):\n",
    "                test_keys.append(c)\n",
    "            else:\n",
    "                train_keys.append(c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                 | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointcloudJitter\n",
      "PointcloudJitter\n",
      "0.05\n",
      "PointcloudJitter\n",
      "model DGCNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhounie\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/chiche/advbench/notebooks/wandb/run-20220905_160106-31fb4qk1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"https://wandb.ai/hounie/ood-modelnet40/runs/31fb4qk1\" target=\"_blank\">finalPointcloudJitter Laplacian_DALE_PD_Reverse 0 1</a></strong> to <a href=\"https://wandb.ai/hounie/ood-modelnet40\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Rand_Aug_Batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:02, ?it/s]\u001b[A\n",
      "  0%|                                                                 | 0/18 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 9.77 GiB (GPU 0; 47.54 GiB total capacity; 19.96 GiB already allocated; 4.18 GiB free; 27.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal train_acc_adv_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mattack_name: train_adv_acc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal train_acc_adv_mean_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mattack_name: train_adv_acc_mean, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal train_loss_adv_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mattack_name: train_adv_loss,\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss_adv_mean_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mattack_name: loss\u001b[38;5;241m.\u001b[39mmean()})\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     test_adv_acc, test_adv_acc_mean, test_adv_acc_bal, test_adv_acc_mean_bal, adv_loss, accs, loss, deltas \u001b[38;5;241m=\u001b[39m \u001b[43mmisc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madv_accuracy_loss_delta_balanced\u001b[49m\u001b[43m(\u001b[49m\u001b[43malgorithm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_ldr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugs_per_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_eval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Adversarial Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_adv_acc)\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Balanced Adversarial Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_adv_acc_bal)\n",
      "File \u001b[0;32m~/advbench/notebooks/../advbench/lib/misc.py:287\u001b[0m, in \u001b[0;36madv_accuracy_loss_delta_balanced\u001b[0;34m(algorithm, loader, device, attack, max_batches, augs_per_batch, batched)\u001b[0m\n\u001b[1;32m    285\u001b[0m elif len(attacked) == 3:\n\u001b[1;32m    286\u001b[0m adv_imgs, delta, labels = attacked\n\u001b[0;32m--> 287\u001b[0m output = algorithm.predict(adv_imgs)\n\u001b[1;32m    288\u001b[0m loss = algorithm.classifier.loss(output, labels, reduction='none')\n\u001b[1;32m    289\u001b[0m pred = output.argmax(dim=1)\n",
      "File \u001b[0;32m~/advbench/notebooks/../advbench/algorithms.py:73\u001b[0m, in \u001b[0;36mAlgorithm.predict\u001b[0;34m(self, imgs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, imgs):\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/daug/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/advbench/notebooks/../advbench/networks.py:93\u001b[0m, in \u001b[0;36mModelWrapper.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/daug/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/advbench/notebooks/../advbench/models/dgcnn.py:126\u001b[0m, in \u001b[0;36mDGCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    123\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[1;32m    124\u001b[0m x1 \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 126\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mget_graph_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)\n\u001b[1;32m    128\u001b[0m x2 \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/advbench/notebooks/../advbench/models/dgcnn.py:48\u001b[0m, in \u001b[0;36mget_graph_feature\u001b[0;34m(x, k, idx, device)\u001b[0m\n\u001b[1;32m     45\u001b[0m feature \u001b[38;5;241m=\u001b[39m feature\u001b[38;5;241m.\u001b[39mview(batch_size, num_points, k, num_dims) \n\u001b[1;32m     46\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(batch_size, num_points, \u001b[38;5;241m1\u001b[39m, num_dims)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, k, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m feature \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m feature\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 9.77 GiB (GPU 0; 47.54 GiB total capacity; 19.96 GiB already allocated; 4.18 GiB free; 27.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "data_dir = '../advbench/data'\n",
    "device = DEVICE\n",
    "failed = []\n",
    "#algorithms = [\"MH_DALE_PD_Reverse\", \"Gaussian_DALE_PD_Reverse\", \"Laplacian_DALE_PD_Reverse\", \"Adversarial_Smoothed_MH\"]\n",
    "n_aug = {\"Rand_Aug_Batch\":100,\"Fo_SGD\":10}\n",
    "t_attacks = [k for k in n_aug.keys()]\n",
    "for exp_id in tqdm(df[\"id\"]):\n",
    "        if True:\n",
    "            api = wandb.Api(timeout=50)\n",
    "            exp = df[df[\"id\"]==exp_id]\n",
    "            dataset =  exp[\"dataset\"].values[0]\n",
    "            algorithm = \"ERM\"\n",
    "            perturbation = exp[\"perturbation\"].values[0]\n",
    "            print(perturbation)\n",
    "            model = exp[\"model\"].values[0]\n",
    "            if True:\n",
    "                project = f\"OOD-{dataset}\"\n",
    "                t_hparams = exp[test_keys].to_dict(orient='index')[exp.index.values[0]]\n",
    "                test_hparams = {}\n",
    "                for k, v in t_hparams.items():\n",
    "                    test_hparams[k.replace(\"test_\",\"\")] = v\n",
    "                print(exp.perturbation.values[0])\n",
    "                if exp.perturbation.values[0] == 'SE':\n",
    "                    hparams['epsilon'] = torch.tensor([hparams[f'epsilon_{i}'] for i in (\"rot\",\"tx\",\"ty\")]).to(device)\n",
    "                    test_hparams['epsilon'] = torch.tensor([test_hparams[f'epsilon_{tfm}'] for tfm in (\"rot\",\"tx\",\"ty\")]).to(device)\n",
    "                elif exp.perturbation.values[0] =='PointcloudTranslation':\n",
    "                    hparams['epsilon'] = torch.tensor([hparams['epsilon_tx'] for i in range(3)] + [hparams['epsilon_ty'] for i in range(3)]).to(device)\n",
    "                    test_hparams['epsilon'] = torch.tensor([test_hparams['epsilon_tx'] for i in range(3)] + [test_hparams['epsilon_ty'] for i in range(3)]).to(device)\n",
    "\n",
    "                hparams = exp[train_keys].to_dict(orient='index')[exp.index.values[0]]\n",
    "                hparams['model'] = model\n",
    "                test_hparams['epsilon'] = hparams['epsilon']\n",
    "                print(hparams['epsilon'])\n",
    "                hparams['batched'] = False\n",
    "                test_hparams['batched'] = False\n",
    "                hparams['worst_of_k_steps'] =  100\n",
    "                test_hparams['worst_of_k_steps'] =  100\n",
    "                if \"augment\" in hparams:\n",
    "                    aug = hparams[\"augment\"]\n",
    "                else:\n",
    "                    aug = True\n",
    "                dataset = vars(datasets)[dataset](data_dir, augmentation = aug)\n",
    "                train_ldr, val_ldr, test_ldr = datasets.to_loaders(dataset, hparams, device=device)\n",
    "                algorithm = load_weights(exp[\"weights\"].values[0], dataset, device=DEVICE, hparams=hparams)           \n",
    "                test_attacks = {a: vars(attacks)[a](algorithm.classifier, test_hparams, DEVICE, perturbation=hparams[\"perturbation\"]) for a in t_attacks}\n",
    "                wandb.init(project=project, resume=exp_id)\n",
    "                if False:\n",
    "                    train_clean_acc, train_clean_mean_acc, train_clean_loss = misc.accuracy_mean_overall_loss(algorithm, train_ldr, device, max_batches=100)\n",
    "                    val_clean_acc, val_clean_mean_acc, val_clean_loss = misc.accuracy_mean_overall_loss(algorithm, val_ldr, device)\n",
    "                    test_clean_acc, test_clean_mean_acc, test_clean_loss = misc.accuracy_mean_overall_loss(algorithm, test_ldr, device)\n",
    "                    wandb.log({'train_clean_loss': train_clean_loss,'train_clean_acc': train_clean_acc, 'train_clean_acc_bal': train_clean_mean_acc})\n",
    "                    wandb.log({'best_val_clean_loss': val_clean_loss, 'best_val_clean_acc': val_clean_acc, 'best_val_clean_acc_bal': val_clean_mean_acc})\n",
    "                    wandb.log({'test_clean_loss': test_clean_loss,'test_clean_acc': test_clean_acc, 'test_clean_acc_bal': test_clean_mean_acc})\n",
    "                for attack_name, attack in test_attacks.items():\n",
    "                    print(f\"Logging {attack_name}...\")\n",
    "                    if exp.dataset.values[0] != \"modelnet40\":\n",
    "                        test_adv_acc, test_adv_acc_mean, adv_loss, accs, loss, deltas = misc.adv_accuracy_loss_delta(algorithm, test_ldr, device, attack, augs_per_batch = n_aug[attack_name])\n",
    "                        train_adv_acc, train_adv_acc_mean, train_adv_loss, train_accs, train_loss, train_deltas = misc.adv_accuracy_loss_delta(algorithm, val_ldr, device, attack, augs_per_batch = n_aug[attack_name])\n",
    "                        wandb.log({'final test_acc_adv_'+attack_name: test_adv_acc, 'final test_acc_adv_mean'+attack_name: test_adv_acc_mean, 'final test_loss_adv_'+attack_name: adv_loss,\n",
    "                        'test_loss_adv_mean_'+attack_name: loss.mean()})\n",
    "                        wandb.log({'final train_acc_adv_'+attack_name: train_adv_acc, 'final train_acc_adv_mean_'+attack_name: train_adv_acc_mean, 'final train_loss_adv_'+attack_name: train_adv_loss,\n",
    "                        'train_loss_adv_mean_'+attack_name: loss.mean()})\n",
    "                    else:\n",
    "                        test_adv_acc, test_adv_acc_mean, test_adv_acc_bal, test_adv_acc_mean_bal, adv_loss, accs, loss, deltas = misc.adv_accuracy_loss_delta_balanced(algorithm, test_ldr, device, attack, augs_per_batch=hparams[\"n_eval\"])\n",
    "                        print(\"Test Adversarial Accuracy:\", test_adv_acc)\n",
    "                        print(\"Test Balanced Adversarial Accuracy:\", test_adv_acc_bal)\n",
    "                        train_adv_acc, train_adv_acc_mean, train_adv_acc_bal, train_adv_acc_mean_bal, adv_loss, train_accs, train_loss, train_deltas = misc.adv_accuracy_loss_delta_balanced(algorithm, train_ldr_small, device, attack, augs_per_batch=hparams[\"n_eval\"])\n",
    "                        print(\"Train Adversarial Accuracy:\", test_adv_acc)\n",
    "                        print(\"Train Balanced Adversarial Accuracy:\", test_adv_acc_bal)\n",
    "                        wandb.log({'test_adv_acc_'+attack_name: test_adv_acc,'test_adv_acc_mean_'+attack_name: test_adv_acc_mean, 'test_loss_adv_'+attack_name: loss.mean(),\n",
    "                         'test_adv_acc_bal_'+attack_name: test_adv_acc_bal, 'test_adv_acc_mean_bal_'+attack_name: test_adv_acc_mean_bal, 'epoch': epoch, 'step':step})\n",
    "                        wandb.log({'train_adv_acc_'+attack_name: train_adv_acc,'train_adv_acc_mean_'+attack_name: train_adv_acc_mean, 'train_loss_adv_'+attack_name: loss.mean(),\n",
    "                         'train_adv_acc_bal_'+attack_name: train_adv_acc_bal, 'train_adv_acc_mean_bal_'+attack_name: train_adv_acc_mean_bal, 'epoch': epoch, 'step':step})                                                   \n",
    "                wandb.finish(quiet=True)\n",
    "        else:\n",
    "            failed.append(exp_id)\n",
    "\n",
    "with open('failed.txt', 'w') as f:\n",
    "    for line in failed:\n",
    "        f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65f58aa27a38851e3e9850fef15fa7db5088b1b5f537a1afba292c768d907c52"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
