{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import matplotlib.colors as mcolors\n",
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from advbench.datasets import MNIST, STL10\n",
    "from advbench.datasets import to_loaders\n",
    "from advbench.algorithms import ERM, Augmentation, Adversarial_Worst_Of_K, Adversarial_PGD\n",
    "from advbench.attacks import Fo_Adam\n",
    "from advbench import hparams_registry\n",
    "from advbench.lib import  misc\n",
    "import torch\n",
    "from advbench.lib.transformations import se_matrix, angle_to_rotation_matrix, se_transform\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as tt\n",
    "import tarfile\n",
    "from torch import nn\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from advbench.scripts.train import PD_ALGORITHMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import matplotlib.colors as mcolors\n",
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from advbench.datasets import to_loaders\n",
    "from advbench.algorithms import ERM, Augmentation, Adversarial_Worst_Of_K, Adversarial_PGD\n",
    "from advbench.attacks import Fo_Adam\n",
    "from advbench import hparams_registry\n",
    "from advbench.lib import  misc\n",
    "import torch\n",
    "from advbench.lib.transformations import se_matrix, angle_to_rotation_matrix, se_transform\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from humanfriendly import format_timespan\n",
    "\n",
    "\n",
    "from advbench import datasets\n",
    "from advbench import algorithms\n",
    "from advbench import attacks\n",
    "from advbench import hparams_registry\n",
    "from advbench.lib import misc, meters, plotting, logging\n",
    "from torch.cuda.amp import autocast\n",
    "from torchsummary import summary\n",
    "DEVICE = \"cuda:1\"\n",
    "DOWNLOAD_WEIGHTS = True\n",
    "PULL_METRICS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(weight_path, dataset, device=DEVICE, hparams={}):       \n",
    "        kw_args = {\"perturbation\": hparams[\"perturbation\"]}\n",
    "        if hparams[\"algorithm\"] in PD_ALGORITHMS: \n",
    "            if hparams[\"algorithm\"].endswith(\"Reverse\"):\n",
    "                kw_args[\"init\"] = 0.0\n",
    "            else:\n",
    "                kw_args[\"init\"] = 1.0\n",
    "        print(hparams[\"perturbation\"])\n",
    "        algorithm = vars(algorithms)[hparams[\"algorithm\"]](\n",
    "        dataset.INPUT_SHAPE, \n",
    "        dataset.NUM_CLASSES,\n",
    "        hparams,\n",
    "        device,\n",
    "        **kw_args).to(device)\n",
    "        w_dict = torch.load(weight_path,map_location=DEVICE)\n",
    "        #print(weight_dict.keys())\n",
    "        #if db==\"mnist\":\n",
    "        weight_dict = {}\n",
    "        for s,v in w_dict.items():\n",
    "                if \"classifier\" in s and \"model\" not in s:\n",
    "                        weight_dict[s.replace('classifier', 'classifier.model')] = v\n",
    "                else:\n",
    "                        weight_dict[s] = v \n",
    "        algorithm.load_state_dict(weight_dict)\n",
    "        return algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for modelnet40\n",
      "72 runs found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 0/72 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-output/finalPointcloudJitter Adversarial_Smoothed DGCNN 4_ckpt.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▉                                                                  | 2/72 [00:00<00:11,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finalPointcloudJitter Adversarial_Smoothed 0 4 29ebt6zd failed\n",
      "train-output/paretoPointcloudJitter Beta_PD_Reverse DGCNN 0_ckpt.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▊                                                                 | 3/72 [00:01<00:28,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-output/paretoPointcloudJitter Beta_PD_Reverse DGCNN 0_ckpt.pkl\n"
     ]
    }
   ],
   "source": [
    "if PULL_METRICS:\n",
    "    api = wandb.Api(timeout=50)\n",
    "    dsets = [\"modelnet40\"]#[\"STL10\", \"CIFAR100\"]\n",
    "    #results_dfs = {}\n",
    "    entity = \"hounie\"\n",
    "    all_runs_list = []\n",
    "    for dataset in dsets:\n",
    "        print(\"Fetching data for {}\".format(dataset))\n",
    "        project = f\"OOD-{dataset}\"\n",
    "        base = f\"../trained_weights/{project}\"\n",
    "        Path( base ).mkdir( parents=True, exist_ok=True )\n",
    "        runs = api.runs(f\"{entity}/{project}\")\n",
    "        print(f\"{len(runs)} runs found\")\n",
    "        for run in tqdm(runs):\n",
    "            if run.state == \"finished\" or (dataset==\"modelnet40\" and run.state != \"running\"):\n",
    "                id = run.id\n",
    "                run = api.run(f\"{entity}/{project}/{id}\")\n",
    "                tmp_path = os.path.join(base, f\"tmp\")\n",
    "                weight_dir = os.path.join(base, run.name)\n",
    "                path = os.path.join(weight_dir, f\"{run.id}.pkl\")\n",
    "                Path( weight_dir ).mkdir( parents=True, exist_ok=True )\n",
    "                results = {**run.summary, **run.config, \"weights\": path, \"id\": run.id, \"name\":run.name}\n",
    "                if DOWNLOAD_WEIGHTS:\n",
    "                    try:\n",
    "                        print(f\"train-output/{run.name[:-4]} DGCNN {run.name[-1]}_ckpt.pkl\")\n",
    "                        f = run.file(f\"train-output/{run.name[:-4]} DGCNN {run.name[-1]}_ckpt.pkl\").download(tmp_path, replace=True) \n",
    "                        os.rename(f.name, path)\n",
    "                        all_runs_list.append(results)\n",
    "                    except:\n",
    "                        print(f\"{run.name} {run.id} failed\")\n",
    "                        \n",
    "    df = pd.DataFrame(all_runs_list)\n",
    "    df.to_csv(f\"./results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./results.csv\")\n",
    "test_keys = []\n",
    "train_keys = []\n",
    "for c in df.columns:\n",
    "        if \"loss\" not in c and \"acc\" not in c:\n",
    "            if c.startswith(\"test\"):\n",
    "                test_keys.append(c)\n",
    "            else:\n",
    "                train_keys.append(c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "CLEAN_METRICS = False\n",
    "data_dir = '../advbench/data'\n",
    "device = DEVICE\n",
    "failed = []\n",
    "n_aug = {\"Fo_PGD\": 1}\n",
    "t_attacks = [k for k in n_aug.keys()]\n",
    "for exp_id in tqdm(df[\"id\"]):\n",
    "        if True:\n",
    "            api = wandb.Api(timeout=50)\n",
    "            exp = df[df[\"id\"]==exp_id]\n",
    "            dataset =  exp[\"dataset\"].values[0]\n",
    "            perturbation = exp[\"perturbation\"].values[0]\n",
    "            print(perturbation)\n",
    "            model = exp[\"model\"].values[0]\n",
    "            if True:\n",
    "                project = f\"OOD-{dataset}\"\n",
    "                t_hparams = exp[test_keys].to_dict(orient='index')[exp.index.values[0]]\n",
    "                test_hparams = {}\n",
    "                for k, v in t_hparams.items():\n",
    "                    test_hparams[k.replace(\"test_\",\"\")] = v\n",
    "                print(exp.perturbation.values[0])\n",
    "                if exp.perturbation.values[0] == 'SE':\n",
    "                    hparams['epsilon'] = torch.tensor([hparams[f'epsilon_{i}'] for i in (\"rot\",\"tx\",\"ty\")]).to(device)\n",
    "                    test_hparams['epsilon'] = torch.tensor([test_hparams[f'epsilon_{tfm}'] for tfm in (\"rot\",\"tx\",\"ty\")]).to(device)\n",
    "                elif exp.perturbation.values[0] =='PointcloudTranslation':\n",
    "                    hparams['epsilon'] = torch.tensor([hparams['epsilon_tx'] for i in range(3)] + [hparams['epsilon_ty'] for i in range(3)]).to(device)\n",
    "                    test_hparams['epsilon'] = torch.tensor([test_hparams['epsilon_tx'] for i in range(3)] + [test_hparams['epsilon_ty'] for i in range(3)]).to(device)\n",
    "\n",
    "                hparams = exp[train_keys].to_dict(orient='index')[exp.index.values[0]]\n",
    "                hparams['model'] = model\n",
    "                test_hparams['epsilon'] = hparams['epsilon']\n",
    "                print(hparams['epsilon'])\n",
    "                hparams['batched'] = True\n",
    "                test_hparams['batched'] = True\n",
    "                if \"augment\" in hparams:\n",
    "                    aug = hparams[\"augment\"]\n",
    "                else:\n",
    "                    aug = True\n",
    "                dataset = vars(datasets)[dataset](data_dir, augmentation = aug)\n",
    "                train_ldr, val_ldr, test_ldr = datasets.to_loaders(dataset, hparams, device=device)\n",
    "                algorithm = load_weights(exp[\"weights\"].values[0], dataset, device=DEVICE, hparams=hparams)           \n",
    "                test_attacks = {a: vars(attacks)[a](algorithm.classifier, test_hparams, DEVICE, perturbation=hparams[\"perturbation\"]) for a in t_attacks}\n",
    "                wandb.init(project=project, resume=exp_id)\n",
    "                if CLEAN_METRICS:\n",
    "                    train_clean_acc, train_clean_mean_acc, train_clean_loss = misc.accuracy_mean_overall_loss(algorithm, train_ldr, device, max_batches=100)\n",
    "                    val_clean_acc, val_clean_mean_acc, val_clean_loss = misc.accuracy_mean_overall_loss(algorithm, val_ldr, device)\n",
    "                    test_clean_acc, test_clean_mean_acc, test_clean_loss = misc.accuracy_mean_overall_loss(algorithm, test_ldr, device)\n",
    "                    wandb.log({'train_clean_loss': train_clean_loss,'train_clean_acc': train_clean_acc, 'train_clean_acc_bal': train_clean_mean_acc})\n",
    "                    wandb.log({'best_val_clean_loss': val_clean_loss, 'best_val_clean_acc': val_clean_acc, 'best_val_clean_acc_bal': val_clean_mean_acc})\n",
    "                    wandb.log({'test_clean_loss': test_clean_loss,'test_clean_acc': test_clean_acc, 'test_clean_acc_bal': test_clean_mean_acc})\n",
    "                for attack_name, attack in test_attacks.items():\n",
    "                    print(f\"Logging {attack_name}...\")\n",
    "                    test_adv_acc, test_adv_acc_mean, test_adv_acc_bal, test_adv_acc_mean_bal, adv_loss, accs, loss, deltas = misc.adv_accuracy_loss_delta_balanced(algorithm, test_ldr, device, attack, augs_per_batch=1)\n",
    "                    print(\"Test Adversarial Accuracy:\", test_adv_acc)\n",
    "                    print(\"Test Balanced Adversarial Accuracy:\", test_adv_acc_bal)\n",
    "                    train_adv_acc, train_adv_acc_mean, train_adv_acc_bal, train_adv_acc_mean_bal, adv_loss, train_accs, train_loss, train_deltas = misc.adv_accuracy_loss_delta_balanced(algorithm, val_ldr, device, attack, augs_per_batch=1)\n",
    "                    print(\"Train Adversarial Accuracy:\", train_adv_acc)\n",
    "                    print(\"Train Balanced Adversarial Accuracy:\", train_adv_acc_bal)\n",
    "                    wandb.log({'test_acc_adv_'+attack_name: test_adv_acc,'test_acc_adv_mean_'+attack_name: test_adv_acc_mean, 'test_loss_adv_'+attack_name: loss.mean(),\n",
    "                     'test_acc_adv_bal_'+attack_name: test_adv_acc_bal, 'test_acc_adv_mean_bal_'+attack_name: test_adv_acc_mean_bal})\n",
    "                    wandb.log({'train_acc_adv_'+attack_name: train_adv_acc,'train_acc_adv_mean_'+attack_name: train_adv_acc_mean, 'train_loss_adv_'+attack_name: loss.mean(),\n",
    "                     'train_acc_adv_bal_'+attack_name: train_adv_acc_bal, 'train_acc_adv_mean_bal_'+attack_name: train_adv_acc_mean_bal})                                                   \n",
    "                wandb.finish(quiet=True)\n",
    "        else:\n",
    "            failed.append(exp_id)\n",
    "\n",
    "with open('failed.txt', 'w') as f:\n",
    "    for line in failed:\n",
    "        f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65f58aa27a38851e3e9850fef15fa7db5088b1b5f537a1afba292c768d907c52"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
